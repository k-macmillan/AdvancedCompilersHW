% Assignment 1
\documentclass{article}
\usepackage[left=2cm, right=2cm, top=2cm]{geometry}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PACKAGES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}                   % PNGs
\usepackage{hyperref}                   % Hyperlinks
\usepackage{amsmath}
\usepackage{algorithm}                  % Algorithms
\usepackage{algpseudocode}              % Algorithms
\usepackage{pdfpages}                   % Include PDFs

\hypersetup{
    colorlinks,
    linkcolor=black
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagenumbering{gobble}

\title{\textbf{Assignment \#1}}
\author{MacMillan, Kyle}
\date{October 10, 2018}


\begin{document}

\maketitle
\addcontentsline{toc}{section}{Title}

\newpage
\pagenumbering{roman}   % Set TOC page numbering to lowercase roman numerals
\tableofcontents
\addcontentsline{toc}{section}{Table of Contents}

\newpage
\listoffigures
\addcontentsline{toc}{section}{List of Figures}
\listoftables
\addcontentsline{toc}{section}{List of Tables}

% \listofalgorithms
% \addcontentsline{toc}{section}{List of Algorithms}

\newpage
\pagenumbering{arabic}  % Set content page numbering to arabic numerals
% Setup Hyperlinks for the rest of the document
\hypersetup{
    citecolor=blue,
    filecolor=black,
    linkcolor=blue,
    urlcolor=blue
}

\setcounter{page}{1}
\section[Problem 1]{Briefly explain the difference between}
\subsection[Compilers and Interpreters]{A compiler and an interpreter}
Compilers are different from interpreters or they would not be separate things. 
In general terms a compiler takes something and turns it into something else. 
An interpreter does the same thing but not as efficiently. The compiler we use 
to compile C\texttt{++} will read through our code and reduce it to assembly 
instructions for the machine we are on. While doing this it will evaluate some 
parts of the code and place things in an ``optimal'' ordering. An interpreter 
does not look at the code until execution, meaning it has no room to perform 
optimizations. Another difference is that interpreters are able to take code on 
the fly, whereas a compiled language must have everything at compile time. 

\subsection[Statically and Dynamically Typed Languages]{A statically typed 
language and a dynamically typed language}
Statically typed languages strictly enforce \textit{type}, whereas dynamically 
typed languages determine which \textit{type} to use. There are two primary 
benefits to statically typed languages:\\
\begin{itemize}
    \item type-safe -- You must declare the type and it will be enforced
    \item speed -- Knowing the type ahead of time means it doesn't have to 
    figure it out on the fly
\end{itemize}

A dynamically typed language is able to determine the type on the fly which 
reduces development time but can also be confusing. In Python, for example, a 
function with a variable named ``flow''. A user may not initially know if flow 
is a string such as \textit{`fast', `normal'} or \textit{`slow'}, or a float 
such as a flow rate. This confusion can make maintenance more difficult. It can 
also hamper someone trying to learn the codebase. There are pros and cons of 
both that need to be taken into consideration when choosing a language.

\subsection[JIT Compiler and Interpreters]{A just-in-time compiler and an 
interpreter}
A just-in-time (JIT) compiler compiles as you send it commands, meaning at 
runtime. A JIT, such as what Java uses, will take the code and compile it to 
bytecode. An interpreter executes instructions. A JIT will have marginally 
better performance compared to an interpreter.

\subsection[Top-Down and Bottom-Up Parsing]{Top-down parsing and bottom-up 
parsing}
Top-down (TD) and bottom-up (BU) parsing refers to the methods of constructing 
a parse tree. As can be assumed, they each begin at their respective ``ends'' 
of a tree. TD parsers can be attacked with a predictive \textit{LL(k)} method 
where \textit{LL} means it descends the left nodes and has a look-ahead of 
\textit{k}. BU parsing involves constructing a parse tree from a given input by 
starting at the bottom, ascending towards the root. BU parsing can use a 
shift-reduce method where the input string is reduced by shifting out the 
left-most element of the input to be evaluated. A tool for both Top-Down and 
Bottom-Up parsers is the \textbf{FIRST} and \textbf{FOLLOW} method.




\newpage
\section[Problem 2]{Let L be the language \{$abxba$ $\vert$ $x$ is any string 
of $a$'s, $b$'s, and $c$'s not containing the substring $ba$\}}
\subsection[Minimum-State DFA]{Construct a minimum-state deterministic finite 
automaton for L}
The wording on this is a little ambiguous and I'm going to take it to mean that 
the string denoted by $x$ can be an empty string because technically the empty 
string does not contain $ba$. It could also be interpreted that the string $x$ 
must contain at least one $a$, $b$, and $c$. This assignment is hard/long enough 
as is and I don't believe that was the intent.

Any string of $a$'s, $b$'s, and $c$'s not containing the substring $ba$ could 
be rewritten as:

\begin{equation}
y = (a^\ast b^\ast c^\ast)^\ast
\end{equation}

\begin{equation}
x \subset y \mid \{ba\} \cap x = \varepsilon
\end{equation}

In order for $ba$ to not intersect $x$ we have to ensure the minimum-state DFA 
cannot go from $b \to\ a$. The visualization is dentoted in Figure \ref{fig:p2-1}. 
Blue denotes the $x$ section and orange are empty sets. Of special note is that 
where $b$ terminates it cannot pass \varepsilon.

\begin{figure}[hc]
\centering
\includegraphics[width=0.5\textwidth]{images/p2-1}}
\caption{Minimum-State DFA}
\label{fig:p2-1}
\end{figure}


\subsection[Input String: abbcabcba]{Show how your DFA processes the input 
string abbcabcba}
$ab$ is the standard entry point, which leaves us with $bcabcba$. While sitting 
at the $a$ node it will advance to $b$, then to $c$, and back to $a$, leaving us 
with $bcba$. From $a$ it will advance to $b$, then to $c$, exiting the ``$x$'' 
portion of our DFA, following $ba$ to $q_{final}$. This process is outlined 
in Figure \ref{fig:p2-2}.

\begin{figure}[hc]
\centering
\includegraphics[width=0.5\textwidth]{images/p2-2}}
\caption{Evaluating abbcabcba}
\label{fig:p2-2}
\end{figure}

\subsection[Input String: abbcababa]{Show how your DFA processes the input 
string abbcababa}
$ab$ is the standard entry point, which leaves us with $bcababa$. While sitting 
at the $a$ node it will advance to $b$, then to $c$, and back to $a$, leaving us 
with $baba$. From $a$ it will advance to $b$, there is no path from $b$ to $a$, 
so it will hop to $q_{final}$ and still have characters left to evaluate, 
creating a critical failure. The process is outlined in Figure 
\ref{fig:p2-3}.

\begin{figure}[hc]
\centering
\includegraphics[width=0.5\textwidth]{images/p2-3}}
\caption{Evaluating abbcababa}
\label{fig:p2-3}
\end{figure}

\subsection[Regular Expression for L]{Construct a regular expression for L}
\begin{equation}
ab (a | b^\ast c | c)^\ast b^\ast ba
\end{equation}

\subsection[Regular Expression generate: abbcabcba]{Show how your regular 
expression generates the input string abbcabcba}
\begin{tabular}{llll}
    ab & \to & $ab$ & ab \\
    bc & \to & $b^\ast c$ & abbc \\
    a & \to & $a^\ast$ & abbca \\
    bc & \to & $b^\ast c$ & abbcabc \\
    ba & \to & $ab$ & abbcabcba \\
\end{tabular}






\newpage
\section[Problem 3]{Let L be the set of all strings of a's and b's with the 
same number of a's as b's}
\subsection[LL1 Grammar]{Construct an LL(1) grammar that generates L}
\begin{tabular}{lll}$
$V = $& $\{S, A, B\}$ \\
$T = $& $\{a, b\}$ \\
$P = $& $\{$ \\
& & $S \to SASBS$ \\
& & $S \to SBSAS$ \\
& & $S \to \varepsilon$ \\
& & $A \to a$ \\
& & $B \to b$ \\
& $\}$\\
$S = $ & $\{S\}$ \\
\end{tabular}
\\

\noindent Where each of those components is a part of the grammar defined by:
\begin{equation}
G = \langle V, T, P, S \rangle
\end{equation}

\subsection[Generation Explanation]{Explain how your grammar generates L}
In the case of an empty set we simply apply the production $S \to \varepsilon$. 
Let's assume the next simplest case: $ab$. Figure \ref{fig:p3-2} shows the steps 
taken to generate input string $ab$ with the given grammar. Essentially we treat 
start with $S$ since it is our $start position$. Given a look ahead of $1$ we 
can assume the production rule $S \to SASBS$ instead of $S \to SBSAS$.

\begin{figure}[hc]
\centering
\includegraphics[width=0.75\textwidth]{images/p3-2}}
\caption[LL1 Grammar ``ab'']{Simple LL1 grammar where the input string is ``ab''}
\label{fig:p3-2}
\end{figure}

\subsection[Proof of LL(1)]{Prove that your grammar is LL(1)}
filler

\subsection[Predictive Parse Table]{Construct a predictive parsing table for your 
grammar}
\begin{table}[h]
    \caption{Predictive Parse Table}
    \centering
    \begin{tabular}{ | l | c | c | c |}
        \hline
          & $a$ & $b$ & \$ \\ \hline
        $S$ & $S \to SASBS$ & $S \to SBSAS$ & $\varepsilon$ \\ \hline
        $A$ & $A \to a$ & &  \\ \hline
        $B$ &  & $B \to b$ & \\
        \hline
    \end{tabular}
\end{table}

\subsection[Predictive Parser: abbbaa]{Show how your predictive parser 
processes the input string abbbaa}
Figure \ref{fig:p3-5} details the walkthrough of input string $abbbaa$.

\begin{figure}[hc]
\centering
\includegraphics[width=0.75\textwidth]{images/p3-5}}
\caption[LL1 Grammar ``abbbaa'']{LL1 grammar where the input string is ``abbbaa''}
\label{fig:p3-5}
\end{figure}




\newpage
\section[Problem 4]{Interactive desk calculator for prefix expressions}
\subsection[Lex/Yac Interpreter]{Using Lex and Yacc or their equivalents, 
implement an interpreter that evaluates newline-terminated input lines of 
prefix arithmetic expressions. The expressions may contain integers and 
operators for addition, subtraction, multiplication, division, and negation. 
The answers are to be integers. Show the Lex-Yacc code for your calculator}
filler

\subsection[Calculator Output]{Show the output generated by your calculator for}

\begin{tabular}{ll}
\indent 1. \texttt{+ 1 - 2 3} & output1 \\
\indent 2. \texttt{+ 1 - 2} & output2 \\
\end{tabular}






\newpage
\section[Problem 5]{A Turing machine is an abstract computer that can do any 
computation that a real computer can do. Because the Turing machine is an 
abstract machine, it does not have the physical properties that a real machine 
has. For example, its tapes are infinite (or at least unbounded for purposes of 
any particular calculation) in length. Another important characteristics is 
that it lacks a clock that is tied to time in the real world.}
\subsection[Turing Machine Double Click]{Explain how a Turing machine can 
detect the fact that two mouse clicks occur close together in real-world time 
even though it has no clock.}

From what I found online the minimum definition for a 
\href{https://en.wikipedia.org/wiki/Turing_machine#Formal_definition}
{Turing Machine} is:
$$M = \langle Q, \Gamma, b, \Sigma, \delta, q_0, F \rangle$$

Anything following that formula is a Turing Machine, but I found nothing 
stating a Turing Machine can't be added to. If $L$ and $R$ shift operations are 
given a time component $t$, which defines an 8th variable for the tuple: 
$\Delta t$, we can assume a Turing Machine would be capable of detecting a double 
click event if the tape were programmed with symbols representing the click 
events.

$$M = \langle Q, \Gamma, b, \Sigma, \delta, q_0, F, \Delta t \rangle$$

Another possibility is to construct an imitation Turing Machine. If we remove 
the abstraction and build something of similar functionality we would be 
constrained by computation time. Using this constraint to our advantage we would 
be able to use an integer symbol that counts the number of times it's able to 
add one to the symbol between key presses, resetting the symbol after checking 
for a double click. If the symbol value is in a predefined range it would be 
considered to be in the state of a double-click.

\end{document}
